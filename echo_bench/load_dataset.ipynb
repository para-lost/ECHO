{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d53ab9d0",
   "metadata": {},
   "source": [
    "# ECHO: Quickstart \n",
    "\n",
    "This is the IPYNB notebook to walk you through loading **ECHO**.\n",
    "\n",
    "## Loading the image_to_image split:\n",
    "### 1) Download images\n",
    "First, run the helper script to fetch images from Twitter/X. This will save files under `data/image_to_image/`:\n",
    "\n",
    "```bash\n",
    "python download_script.py\n",
    "```\n",
    "\n",
    "**IMPORTANT**: The downloaded images are subject to Twitter/Xâ€™s Terms & Policies. You are responsible for ensuring your own compliance and for any actions you take with this data.\n",
    "\n",
    "### 2) A note on content difference\n",
    "\n",
    "Since images are fetched from the public web, individual files may change or disappear over time. To make experiments reproducible, we released CLIP embeddings for the reference images. You can verify your local copies against the references with:\n",
    "\n",
    "```bash\n",
    "python verify_images.py --folder \"data/image_to_image\" --embeddings \"reference_embeddings.json\"\n",
    "```\n",
    "\n",
    "This will print a summary of the verification/checking results.\n",
    "\n",
    "If you have problems downloading the data, please **contact us** at [echo-bench@googlegroups.com](mailto:echo-bench@googlegroups.com)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49718179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "710 ivxXSVAkagWfT6HvE3F6aR 1\n",
      "['ivxXSVAkagWfT6HvE3F6aR', '6aW6H3s3HEuBP6MB55FoH4', 'HEx2VuyZ4brzkAo8LxNUBm', '5y8E8Jwez26MRjyngqJcc2'] 1\n"
     ]
    }
   ],
   "source": [
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from echo_bench_i2i import EchoBenchHFImageToImage, echo_bench_i2i_collate\n",
    "from datasets import load_dataset\n",
    "\n",
    "# load the image-to-image split\n",
    "ds = EchoBenchHFImageToImage(\n",
    "    repo_id=\"echo-bench/echo2025\",\n",
    "    name=\"image_to_image\",\n",
    "    split=\"test\",\n",
    ")\n",
    "\n",
    "print(len(ds), ds[0][\"id\"], len(ds[0][\"input_images\"]))\n",
    "\n",
    "loader = DataLoader(ds, batch_size=4, shuffle=False, collate_fn=echo_bench_i2i_collate)\n",
    "batch = next(iter(loader))\n",
    "print(batch[\"id\"], len(batch[\"input_images\"][0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e2a511",
   "metadata": {},
   "source": [
    "## Loading the text_to_image split:\n",
    "This can be directly accessed by loading the dataset from huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a306002a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb0be583b89a47abaf1808bfa7fb48d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/848 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'prompt', 'prompt_modified', 'prompt_fill_blank', 'input_images', 'output_images', 'community_feedback', 'has_nsfw'],\n",
       "    num_rows: 848\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the text-to-image split\n",
    "ds_text_to_image = load_dataset(\n",
    "    \"echo-bench/echo2025\",\n",
    "    name=\"text_to_image\",\n",
    "    split=\"test\",\n",
    ")\n",
    "ds_text_to_image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a17d67",
   "metadata": {},
   "source": [
    "## Loading the analysis split:\n",
    "This can be directly accessed by loading the dataset from huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6230baf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6df1925c4294414c9893a56a506ec32b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/29336 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'prompt', 'prompt_modified', 'quality', 'community_feedback'],\n",
       "    num_rows: 29336\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the analysis split\n",
    "ds_analysis = load_dataset(\n",
    "    \"echo-bench/echo2025\",\n",
    "    name=\"analysis\",\n",
    "    split=\"test\",\n",
    ")\n",
    "ds_analysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tweetbench",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
