root_path: "example_outputs" # Root path containing all outputs
mode: "gpt" # Backend to use for evaluation; one of ["gpt", "transformers", "qwen", "gemini"]
# Splits to evaluate
split_names: 
  - "text_to_image"
  # - "image_to_image"

gpt_kwargs:
  api_cls: "AsyncOpenAI"

qwen_kwargs:
  model: "qwen/qwen2.5-vl-32b-instruct"
  max_concurrency: 4
  call_kwargs:
    temperature: 0.0

gemini_kwargs:
  model: "google/gemini-2.0-flash-001"
  max_concurrency: 8
  call_kwargs:
    temperature: 0.0
    
transformers_kwargs:
  call_fn: vlm_load_call
  model_cls: AutoModelForVision2Seq
  model_kwargs:
    pretrained_model_name_or_path: "Qwen/Qwen2.5-VL-32B-Instruct"
    load_in_4bit: True
    attn_implementation: "flash_attention_2"
  forward_kwargs:
    max_new_tokens: 512
    batch_size: 8
  gpu_ids: [0,1,2]